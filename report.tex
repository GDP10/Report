\documentclass[a4paper, 12pt]{article}
\usepackage[backend=biber]{biblatex}
\usepackage{graphicx}
\usepackage{caption}

\addbibresource{report.bib}
\nocite{*}

\newcommand{\userstory}[3]{
	\noindent\fbox{
		\parbox{\textwidth}{
			\emph{\textbf{AS A}} {\small #1}\\*\emph{\textbf{I WANT}} {\small #2}\\*\emph{\textbf{SO THAT}} {\small #3}
		}
	}
}

\begin{document}

\begin{titlepage}

	\center

	{\large ELECTRONICS AND COMPUTER SCIENCE}\\[0.2cm]
	{\large FACULTY OF PHYSICAL SCIENCES AND ENGINEERING}\\[0.2cm]
	{\large UNIVERSITY OF SOUTHAMPTON}\\[3cm]

	{\Large Peter Prince}\\[0.2cm]
	{\Large James Robinson}\\[0.2cm]
	{\Large Charles Sherman}\\[0.2cm]
	{\Large Andrew Sullivan}\\[1cm]
	{\Large \today}\\[3cm]

	{\LARGE Aeronautical Event Service}\\[3cm]

	{\large Project Supervisor: Dr Robert Walters}\\[0.2cm]
	{\large Second Examiner: -}\\[2.5cm]

	{\large A project report submitted for the award of}\\[0.2cm]
	{\Large MEng Computer Science}

\end{titlepage}

\begin{abstract}

\end{abstract}

\newpage

\section*{Acknowledgements}

\newpage

\tableofcontents
\newpage

\listoffigures
\newpage

\section{Introduction}
\label{sec:introduction}

\subsection{Project Description}
\subsubsection{Motivation}
Pilots need to be notified of hazards and events that may require them to make changes to their flight plan. Examples of such events includes: closed runways, restricted airspaces, extreme weather conditions and even the presence of migrating birds through an airspace. Currently, flight planners receive such information by pulling 'NOTAM's, or 'Notice to Airmen', and must manually sort through all NOTAMs to find only the notices which are relevant to their flight, which is extremely time consuming. The efficiency of this task could be improved dramatically if the filtering were performed automatically.

\subsubsection{Customer}

The customer for this project was Snowflake Software, a company focused on open data exchange, and various products based on mapping data. Within sprint meetings the company was represented by Eddie Curtis, who expressed the feature requests and gave feedback, representing Snowflake as a whole.

\subsubsection{Goals}

The vision, as stated by Snowflake, was ``To develop a proof of concept push event service for delivering digital NOTAM updates to pilots; to demonstrate the feasibility of using Publish/Subscribe to communicate relevant NOTAMs to flight planners''. From this vision, the goal of the software produced over the course of the project was to explore options and find methods to limit the incoming data to a flight planner to only relevant data by utilising a publish and subscribe model, removing the need for manual filtering and the pulling of relevant NOTAMs by pilots. 

The subscriptions to this service had to be based on the relevancy of NOTAMs to the recipients. This relevancy should be based on simple factors, such as departure and arrival airports, and more complex temporal queries, for example, limiting NOTAMs events to ones relevant only during the course of the flight. The software was required to use open standards for the publish and subscribe architecture, for example: OASIS Web Services Notification or WSN. The software also had to be capable of handling an estimated 10,000 messages per day. These messages come from two sources: the Federal NOTAM Service, which publishes a baseline NOTAM every 28 days, and updated delta files which arrive every 15 minutes. 

\subsection{Background Information}

\subsubsection{NOTAMs}
A `notice to airmen' (NOTAM), is a notice given to airmen about events in a particular airspace or at a particular airport. The events may be hazards that have to be avoided, such as dangerous weather or updates on runway closures, which may or may not be relevant to the flight.

The NOTAMs are delivered as deltas from a baseline of data. For instance, a pilot may be told in a NOTAM that runway 3 has been closed at their destination. They were previously told about the number of alternative runways at the destination airport in a baseline message. Deltas can be either temporary or non-temporary; temporary updates apply for a certain time frame whereas non-temporary updates last indefinitely.

If there are many delta updates, it may be useful to make a snapshot. A snapshot is an updated baseline that is formed from the original baseline and a combination of deltas.

\newpage

\subsubsection{Publish/Subscribe Architecture}

\begin{figure}
\begin{center}
\def\svgwidth{\columnwidth}
\input{broker.pdf_tex}
\end{center}
\caption{Publish/Subscribe Architecture with Broker}
\label{fig:example_net}
\end{figure}

Publish-subscribe is a messaging architecture that allows decoupling between the \emph{producers} and the \emph{consumers} of \emph{messages}. Messages are categorised into \emph{topics}; producers publish messages on a given topic with no knowledge of which (if any) subscribers the topic has, and consumers subscribe to a given topic with no knowledge of which (if any) producers are publishing messages with that topic.

This architecture is generally implemented using a \emph{broker}, which exists as middleware between the producers and consumers. Producers send messages on a given topic to the broker, which then decides which consumers the messages should be forwarded to. Consumers subscribe via the broker to topics theyâ€™re interested in, and the broker forwards relevant messages to them. This architecture has a number of benefits, including providing loose coupling between producers and consumers (since they need no knowledge of each other to make use of this architecture) and facilitating scalability by supporting arbitrary numbers of producers and consumers for any given topic.

In Java, brokers typically implement the Java Message Service (JMS) API provided by Java Enterprise Edition, which offers a consistent interface for communicating with many different message broker implementations.

\newpage

\section{Planning and Organisation}
\label{sec:planning}

The project was built using the Agile software development practices of Scrum, and each sprint followed a similar structure. First, the customer came up with ideas for features which could be worked on in the following sprint. Next, user stories based on these features were created, dividing up the requirements of each feature and helping to create acceptance criteria which would come together to prove acceptance that the feature was successfully implemented.

At the beginning of each sprint, a sprint meeting was held to both close the previous sprint and prepare for the following one. First, features implemented in the previous sprint were demonstrated to the customer, allowing them to track the progress of the project and decide whether the feature had been successfully implemented. In the event the customer was not satisfied with the work done in the sprint, the user stories were kept in the backlog for the following sprint. Otherwise, the customer discussed future features to be implemented and broke the feature up into user stories to be added to the backlog.

Various software was used to carry out this process, including JIRA (access to which was provided by the client) and Cucumber. JIRA is a tracker that manages user stories and their corresponding acceptance criteria as per each feature. User stories within JIRA are stored in the standardised \emph{``As a, I want, So that''} format, with their acceptance criteria written as \emph{``Given, When, Then''}. This format is also used by Cucumber for acceptance tests. Team members on JIRA can choose what user stories to complete or they can be assigned.

Cucumber was used to express the acceptance criteria for each story, allowing them to be converted into automated acceptance tests which could be run using JUnit. The Cucumber features are written in a language called Gherkin. Each Gherkin feature has a number of scenarios that test the aspects of that feature. The scenarios are written such that the implementation of the feature can change without having to rewrite the file. In the JUnit test file methods are called by Cucumber based off regex tags on the methods. For each story, when all acceptance tests passed within JUnit, the user story is removed from the backlog.

\newpage

\section{Implementation}
\subsection{Sprint Breakdown}
\subsubsection{Sprint 1}
In the first sprint meeting the customer laid out a user story epic for the entire project, stating the overall goals and requirements. Shorter term goals for the following sprint were also established, including setting up development environments and source repositories and investigating Apache ActiveMQ, a message queue with filtering capabilities. Once language, development environment and source repository were established, development began.

After working on a basic implementation of ActiveMQ and exploring the documentation available online, it became obvious that it contained no implementation of WS-Notification. One of the requirements stated by the customer was the inclusion of WS-Notification and while this was a soft requirement, meaning that it's inclusion could be forgone if sufficient justification was given, the project was in an early enough stage at this point in development that it was worth exploring other alternatives. Alternatives such as developing our own WS-Notification implementation using CXF.

Apache CXF is an open source framework for producing web services, and after ActiveMQ was deemed unusable, research began into using CXF. Work started by creating a WS-Notification implementation within CXF. Progress in this was slowed significantly by documentation for the framework being extremely limited. While creating this implementation, it was discovered that an implementation existed, undocumented, within Apache CXF. Through experimentation and knowledge gained from attempting to build a bespoke implementation, a basic demo was produced, subscribing a consumer to a preallocated topic and sending out a message through the subscription.

\userstory{flight planner}{to be notified if there is a change to my destination airport for my planned flight.}{I can change my plan in response to events involving airspaces and runways on my route.}

\subsubsection{Sprint 2}

In the second sprint we were set the goals of expanding on the work we had already done. At the end of the first sprint we had a producer, broker and consumer all with hard-coded values for the subscription information. Our target for the end of the second sprint was to have a consumer that subscribed with configurable topics and to have multiple consumers listening to a broker.

During the second sprint planning meeting we made a table of requirements to implement the code for the sprint. At the start of the sprint we had implemented the top row of the table and the target for the end of the sprint was to implement the lowest row from each column. The process works by filling out each layer of the table, one at a time to make sure features could be implemented in feasible steps.

In practice we found that the jump from hard coded values to having everything being configurable was trivial. However creating tests for the code was not as simple as we had hoped. We created a set of Cucumber tests to check that a NOTAM could be sent from a producer, to a broker and out to a set of consumers; we ran into problems with waiting for processes to load up and having time-outs to check if a NOTAM had been received, in sprint 3 this was remedied by moving our tests to a continuous integration server. 

\begin{table}
    \begin{tabular}{|l|l|l|l|}
    \hline
    \emph{Origin}         & \emph{Destination}    & \emph{Route}                 & \emph{Consumers} \\ \hline
    One Hard-Coded & None           & None                  & One       \\ \hline
    Configurable   & One Hard-Coded & One Hard-Coded        & Two       \\ \hline
    ~              & Configurable   & Multiple Hard-Coded   & Multiple  \\ \hline
    ~              & ~              & Multiple Configurable & ~         \\ \hline
    \end{tabular}
\caption{Sprint 2 Table}
\label{tab:sprint2}
\end{table}

\section{Conclusions}
\label{sec:conclusions}

\newpage

\section{Future Work}

\newpage

\addcontentsline{toc}{section}{References}
\sloppy
\printbibliography

\end{document}
