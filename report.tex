\documentclass[a4paper, 12pt]{article}
\usepackage[backend=biber]{biblatex}
\usepackage{graphicx}
\usepackage{caption}

\addbibresource{report.bib}
\nocite{*}

\newcommand{\userstory}[3]{
	\noindent\fbox{
		\parbox{\textwidth}{
			\emph{\textbf{AS A}} {\small #1}\\*\emph{\textbf{I WANT}} {\small #2}\\*\emph{\textbf{SO THAT}} {\small #3}
		}
	}
}

\begin{document}

\begin{titlepage}

	\center

	{\large ELECTRONICS AND COMPUTER SCIENCE}\\[0.2cm]
	{\large FACULTY OF PHYSICAL SCIENCES AND ENGINEERING}\\[0.2cm]
	{\large UNIVERSITY OF SOUTHAMPTON}\\[3cm]

	{\Large Peter Prince}\\[0.2cm]
	{\Large James Robinson}\\[0.2cm]
	{\Large Charles Sherman}\\[0.2cm]
	{\Large Andrew Sullivan}\\[1cm]
	{\Large \today}\\[3cm]

	{\LARGE Aeronautical Event Service}\\[3cm]

	{\large Project Supervisor: Dr Robert Walters}\\[0.2cm]
	{\large Second Examiner: -}\\[2.5cm]

	{\large A project report submitted for the award of}\\[0.2cm]
	{\Large MEng Computer Science}

\end{titlepage}

\begin{abstract}

\end{abstract}

\newpage

\section*{Acknowledgements}

\newpage

\tableofcontents
\newpage

\listoffigures
\newpage

\section{Introduction}
\label{sec:introduction}

\subsection{Project Description}
\subsubsection{Motivation}
Pilots need to be notified of hazards and events that may require them to make changes to their flight plan. Examples of such events includes: closed runways, restricted airspaces, extreme weather conditions and even the presence of migrating birds through an airspace. Currently, flight planners receive such information by pulling 'NOTAM's, or 'Notice to Airmen', and must manually sort through all NOTAMs to find only the notices which are relevant to their flight, which is extremely time consuming. The efficiency of this task could be improved dramatically if the filtering were performed automatically.

\subsubsection{Customer}

The customer for this project was Snowflake Software, a company focused on open data exchange, and various products based on mapping data. Within sprint meetings the company was represented by Eddie Curtis, who expressed the feature requests and gave feedback, representing Snowflake as a whole.

\subsubsection{Goals}

The vision, as stated by Snowflake, was ``To develop a proof of concept push event service for delivering digital NOTAM updates to pilots; to demonstrate the feasibility of using Publish/Subscribe to communicate relevant NOTAMs to flight planners''. From this vision, the goal of the software produced over the course of the project was to explore options and find methods to limit the incoming data to a flight planner to only relevant data by utilising a publish and subscribe model, removing the need for manual filtering and the pulling of relevant NOTAMs by pilots. 

The subscriptions to this service had to be based on the relevancy of NOTAMs to the recipients. This relevancy should be based on simple factors, such as departure and arrival airports, and more complex temporal queries, for example, limiting NOTAMs events to ones relevant only during the course of the flight. The software was required to use open standards for the publish and subscribe architecture, for example: OASIS Web Services Notification or WSN. The software also had to be capable of handling an estimated 10,000 messages per day. These messages come from two sources: the Federal NOTAM Service, which publishes a baseline NOTAM every 28 days, and updated delta files which arrive every 15 minutes. 

\subsection{Background Information}

\subsubsection{NOTAMs}
A `notice to airmen' (NOTAM), is a notice given to airmen about events in a particular airspace or at a particular airport. The events may be hazards that have to be avoided, such as dangerous weather or updates on runway closures, which may or may not be relevant to the flight.

The NOTAMs are delivered as deltas from a baseline of data. For instance, a pilot may be told in a NOTAM that runway 3 has been closed at their destination. They were previously told about the number of alternative runways at the destination airport in a baseline message. Deltas can be either temporary or non-temporary; temporary updates apply for a certain time frame whereas non-temporary updates last indefinitely.

If there are many delta updates, it may be useful to make a snapshot. A snapshot is an updated baseline that is formed from the original baseline and a combination of deltas.

\newpage

\subsubsection{Publish/Subscribe Architecture}

\begin{figure}
\begin{center}
\def\svgwidth{\columnwidth}
\input{broker.pdf_tex}
\end{center}
\caption{Publish/Subscribe Architecture with Broker}
\label{fig:example_net}
\end{figure}

Publish-subscribe is a messaging architecture that allows decoupling between the \emph{producers} and the \emph{consumers} of \emph{messages}. Messages are categorised into \emph{topics}; producers publish messages on a given topic with no knowledge of which (if any) subscribers the topic has, and consumers subscribe to a given topic with no knowledge of which (if any) producers are publishing messages with that topic.

This architecture is generally implemented using a \emph{broker}, which exists as middleware between the producers and consumers. Producers send messages on a given topic to the broker, which then decides which consumers the messages should be forwarded to. Consumers subscribe via the broker to topics theyâ€™re interested in, and the broker forwards relevant messages to them. This architecture has a number of benefits, including providing loose coupling between producers and consumers (since they need no knowledge of each other to make use of this architecture) and facilitating scalability by supporting arbitrary numbers of producers and consumers for any given topic.

In Java, brokers typically implement the Java Message Service (JMS) API provided by Java Enterprise Edition, which offers a consistent interface for communicating with many different message broker implementations.

\subsubsection{Web Services Description Language}

The Web Services Description Language (or WSDL) is an XML based language for describing the interfaces and functionality of a web service. A WSDL file provides a machine readable description of a web service's interface, including the function calls, parameters they expect and return values.\\
Typically, it is used in combination with SOAP to provide a web service, where a client program will read the WSDL, to determine the functions available, and then use SOAP to call them.




\newpage

\section{Planning and Organisation}
\label{sec:planning}

The project was built using the Agile software development practices of Scrum, and each sprint followed a similar structure. First, the customer came up with ideas for features which could be worked on in the following sprint. Next, user stories based on these features were created, dividing up the requirements of each feature and helping to create acceptance criteria which would come together to prove acceptance that the feature was successfully implemented.

At the beginning of each sprint, a sprint meeting was held to both close the previous sprint and prepare for the following one. First, features implemented in the previous sprint were demonstrated to the customer, allowing them to track the progress of the project and decide whether the feature had been successfully implemented. In the event the customer was not satisfied with the work done in the sprint, the user stories were kept in the backlog for the following sprint. Otherwise, the customer discussed future features to be implemented and broke the feature up into user stories to be added to the backlog.

Various software was used to carry out this process, including JIRA (access to which was provided by the client) and Cucumber. JIRA is a tracker that manages user stories and their corresponding acceptance criteria as per each feature. User stories within JIRA are stored in the standardised \emph{``As a, I want, So that''} format, with their acceptance criteria written as \emph{``Given, When, Then''}. This format is also used by Cucumber for acceptance tests. Team members on JIRA can choose what user stories to complete or they can be assigned.

Early on in the project we were given access to Jira on Snowflake's private servers. This allowed us to keep control over our backlog and keep a record of what had been completed. However over the course of the project, the number of steps required to connect to the Snowflake VPN and access Jira as well as the difficulty from never having used the service before, we decided keeping track of the project would be better done through Github, which was already being used as a code repository. The issue tracking features within Github replaced Jira's extensive features (the majority of which far surpassed the requirements of a small project such as ours) and all tasks became issues, still using the standard user story format.

Cucumber was used to express the acceptance criteria for each story, allowing them to be converted into automated acceptance tests which could be run using JUnit. The Cucumber features are written in a language called Gherkin. Each Gherkin feature has a number of scenarios that test the aspects of that feature. The scenarios are written such that the implementation of the feature can change without having to rewrite the file. In the JUnit test file methods are called by Cucumber based off regex tags on the methods. For each story, when all acceptance tests passed within JUnit, the user story is removed from the backlog.

\newpage

\section{Implementation}
\subsection{Sprint Breakdown}
\subsubsection{Sprint 1}
In the first sprint meeting the customer laid out a user story epic for the entire project, stating the overall goals and requirements. Shorter term goals for the following sprint were also established, including setting up development environments and source repositories and investigating Apache ActiveMQ, a message queue with filtering capabilities. Once language, development environment and source repository were established, development began.

After working on a basic implementation of ActiveMQ and exploring the documentation available online, it became obvious that it contained no implementation of WS-Notification. One of the requirements stated by the customer was the inclusion of WS-Notification and while this was a soft requirement, meaning that it's inclusion could be forgone if sufficient justification was given, the project was in an early enough stage at this point in development that it was worth exploring other alternatives. Alternatives such as developing our own WS-Notification implementation using CXF.

Apache CXF is an open source framework for producing web services, and after ActiveMQ was deemed unusable, research began into using CXF. Work started by creating a WS-Notification implementation within CXF. Progress in this was slowed significantly by documentation for the framework being extremely limited. While creating this implementation, it was discovered that an implementation existed, undocumented, within Apache CXF. Through experimentation and knowledge gained from attempting to build a bespoke implementation, a basic demo was produced, subscribing a consumer to a preallocated topic and sending out a message through the subscription.

\userstory{flight planner}{to be notified if there is a change to my destination airport for my planned flight.}{I can change my plan in response to events involving airspaces and runways on my route.}

\subsubsection{Sprint 2}

In the second sprint we were set the goals of expanding on the work we had already done. At the end of the first sprint we had a producer, broker and consumer all with hard-coded values for the subscription information. Our target for the end of the second sprint was to have a consumer that subscribed with configurable topics and to have multiple consumers listening to a broker.

During the second sprint planning meeting we made a table of requirements to implement the code for the sprint. At the start of the sprint we had implemented the top row of the table and the target for the end of the sprint was to implement the lowest row from each column. The process works by filling out each layer of the table, one at a time to make sure features could be implemented in feasible steps.

In practice we found that the jump from hard coded values to having everything being configurable was trivial. However creating tests for the code was not as simple as we had hoped. We created a set of Cucumber tests to check that a NOTAM could be sent from a producer, to a broker and out to a set of consumers; we ran into problems with waiting for processes to load up and having time-outs to check if a NOTAM had been received, in sprint 3 this was remedied by moving our tests to a continuous integration server. 

\begin{table}
    \begin{tabular}{|l|l|l|l|}
    \hline
    \emph{Origin}         & \emph{Destination}    & \emph{Route}                 & \emph{Consumers} \\ \hline
    One Hard-Coded & None           & None                  & One       \\ \hline
    Configurable   & One Hard-Coded & One Hard-Coded        & Two       \\ \hline
    ~              & Configurable   & Multiple Hard-Coded   & Multiple  \\ \hline
    ~              & ~              & Multiple Configurable & ~         \\ \hline
    \end{tabular}
\caption{Sprint 2 Table}
\label{tab:sprint2}
\end{table}

\subsubsection{Sprint 3}

The main focus of sprint 3 was to research the extent of JBoss A-MQ's filtering capabilities, to access its viability for use in the project. Through research in the previous sprint, the prominence of JBoss as a message queue used industrially had become apparent. Research done by Snowflake themselves also suggested that it would be useful for the project. The subject of testing was also brought up, and the implementation of a continuous integration system was decided upon to streamline the implementation of changes to the project. Early on in the sprint, Jenkins was implemented and set up to run tests continuously on the latest version of the project, updating the project's Github page with the outcome of the latest tests.

It was in sprint 3, after the progress made up to that point was shown in the sprint meeting, that the customer expressed a desire for the implementation of spatial and temporal filtering of NOTAMs. The utility of spatial filtering is obvious in the case of flight planning, a flight planner simply defining the start and end point of the journey and then receiving all messages relevant to that geographical space would save considerable time when compared to the alternative of manually subscribing to airspaces and airports which are within range. Temporal filtering would allow a consumer to only receive NOTAMs that are in effect for the duration of their flight, dramatically reducing the number of irrelevant NOTAMs being sent.

In order to perform spatial filtering, latitude and longitude data for every airspace and airfield would be required, as NOTAMs lack information at this level of detail. The information required for temporal filtering is featured in each NOTAM, and only conversion to a usable timestamp format was required.

With these two filtering types being the goal of the sprint, work was split into exploring documentation for implementation instructions and information regarding filtering, in JBoss A-MQ. After a week of investigation it became apparent that JBoss would not allow us to fulfil the requirements of the product, due to its extremely limited filtering implementation. JBoss filtering is restricted exclusively to simple strings, comparing the contents of each message with a given filter and sending based on its presence. This left two options: either forking A-MQ and modifying it to support the required features or dropping it in favour of a message queue which does fulfil those requirements. Basing the decision on the scope of the project and limited remaining time to complete it, it was decided to abandon A-MQ. As it was early in the sprint and the outcome of the decision would dramatically affect the outcome of the sprint, the customer was notified of the decision, to ensure it was satisfactory to them.

\subsubsection{Sprint 4}

The forth sprint meeting consisted of bringing up to speed members of Snowflake in attendance who had not been notified about JBoss A-MQ. As well as the customer representative, Eddie, and the scrum master, Adrian, Alexis Brooker also attended, and after discussing the need for GPS locations in order to perform spatial filtering, Alexis provided access to a HTTP-GET web feature service (WFS), which returns latitude and longitude locations for all European airfields. Ideally, calling this service would be implemented into AES itself, however given the time remaining on the project and the status of the product as a proof of concept, it was elected to simply retrieve data for all airfields and hard-code them into the system for use in spatial queries, knowing that the system could easily be modified to directly call the service and utilise the data if more time was spent on it.

After JBoss A-MQ proved to be a dead end, a new system structure was decided on, with only the consumer side using WS-Notifications to communicate. All remaining communication between brokers and producers was changed to rely on JMS, with converters between WS-Notification topics and JMS filters becoming a primary focus for the sprint. 

\section{Conclusions}
\label{sec:conclusions}

\newpage

\section{Future Work}

\newpage

\addcontentsline{toc}{section}{References}
\sloppy
\printbibliography

\end{document}
